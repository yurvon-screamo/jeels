[database]
path = "~/.keikaku"

# [llm.candle]
# max_sample_len = 8192
# temperature = 0.7
# seed = 299792458
# model_repo = "unsloth/Qwen3-1.7B-GGUF"
# model_filename = "Qwen3-1.7B-Q4_K_M.gguf"
# model_revision = "main"
# tokenizer_repo = "Qwen/Qwen3-1.7B"
# tokenizer_filename = "tokenizer.json"

# [llm.gemini]
# temperature = 0.7
# model = "gemini-pro"

[llm.openai]
temperature = 0.3
# model = "llm_instruct"
model = "llm_thinking"
base_url = "http://10.2.11.6:8001/v1"
env_var_name = "OPENROUTER_API_KEY"

# [embedding.candle]

[embedding.openai]
model = "embedding"
base_url = "http://10.3.168.177:8003/v1"
env_var_name = "OPENROUTER_API_KEY"

[reranker.openai]
model = "reranker"
base_url = "http://10.3.168.177:8002/v1"
env_var_name = "OPENROUTER_API_KEY"

[translation]
temperature = 0.8
seed = 299792458
